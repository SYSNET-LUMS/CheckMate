{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth Path\n",
    "path_to_ground_truth = 'output_images/0_trunc/'\n",
    "\n",
    "# Truncation Values\n",
    "truncation_values = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "\n",
    "# Make a DataFrame to store the results. Rows are image names, columns are truncation values\n",
    "results = pd.DataFrame(columns=truncation_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pgm_opencv(file_path):\n",
    "    # Load PGM image using OpenCV\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the original image as the ground truth and the approximated image as the prediction.\n",
    "# Calculate the F1 score.\n",
    "\n",
    "def calculate_f1_score(original_image, approximated_image):\n",
    "    # Calculate the F1 score\n",
    "    true_positive = np.sum(np.logical_and(original_image, approximated_image))\n",
    "    false_positive = np.sum(np.logical_and(np.logical_not(original_image), approximated_image))\n",
    "    false_negative = np.sum(np.logical_and(original_image, np.logical_not(approximated_image)))\n",
    "\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every image in the ground truth folder, get the corresponding approximated image from output_images/{truncation_value}_trunc folder.\n",
    "# Calculate the F1 score and store it in the results DataFrame.\n",
    "\n",
    "for truncation_value in truncation_values:\n",
    "    path_to_approximated_images = f'output_images/{truncation_value}_trunc/'\n",
    "    for image in os.listdir(path_to_ground_truth):\n",
    "        if image.endswith('.pgm'):\n",
    "            original_image = load_pgm_opencv(path_to_ground_truth + image)\n",
    "            approximated_image = load_pgm_opencv(path_to_approximated_images + image)\n",
    "            ssim_score = ssim(original_image, approximated_image)\n",
    "            results.loc[image, truncation_value] = ssim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>35</th>\n",
       "      <th>40</th>\n",
       "      <th>45</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181091.pgm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914131</td>\n",
       "      <td>0.825784</td>\n",
       "      <td>0.750035</td>\n",
       "      <td>0.679967</td>\n",
       "      <td>0.610584</td>\n",
       "      <td>0.554807</td>\n",
       "      <td>0.505205</td>\n",
       "      <td>0.461486</td>\n",
       "      <td>0.418249</td>\n",
       "      <td>0.375648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302003.pgm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948265</td>\n",
       "      <td>0.904148</td>\n",
       "      <td>0.864201</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>0.774647</td>\n",
       "      <td>0.733985</td>\n",
       "      <td>0.700063</td>\n",
       "      <td>0.665989</td>\n",
       "      <td>0.639136</td>\n",
       "      <td>0.615725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35070.pgm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982869</td>\n",
       "      <td>0.956663</td>\n",
       "      <td>0.932102</td>\n",
       "      <td>0.899477</td>\n",
       "      <td>0.868101</td>\n",
       "      <td>0.841577</td>\n",
       "      <td>0.815345</td>\n",
       "      <td>0.796692</td>\n",
       "      <td>0.768751</td>\n",
       "      <td>0.757586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216066.pgm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.91289</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.745937</td>\n",
       "      <td>0.668292</td>\n",
       "      <td>0.596156</td>\n",
       "      <td>0.528855</td>\n",
       "      <td>0.462882</td>\n",
       "      <td>0.405342</td>\n",
       "      <td>0.354301</td>\n",
       "      <td>0.305052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166081.pgm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.856217</td>\n",
       "      <td>0.793161</td>\n",
       "      <td>0.730775</td>\n",
       "      <td>0.674354</td>\n",
       "      <td>0.624132</td>\n",
       "      <td>0.570448</td>\n",
       "      <td>0.528372</td>\n",
       "      <td>0.485041</td>\n",
       "      <td>0.446398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         5         10        15        20        25        30  \\\n",
       "181091.pgm  1.0  0.914131  0.825784  0.750035  0.679967  0.610584  0.554807   \n",
       "302003.pgm  1.0  0.948265  0.904148  0.864201  0.825288  0.774647  0.733985   \n",
       "35070.pgm   1.0  0.982869  0.956663  0.932102  0.899477  0.868101  0.841577   \n",
       "216066.pgm  1.0   0.91289  0.825792  0.745937  0.668292  0.596156  0.528855   \n",
       "166081.pgm  1.0    0.9283  0.856217  0.793161  0.730775  0.674354  0.624132   \n",
       "\n",
       "                  35        40        45        50  \n",
       "181091.pgm  0.505205  0.461486  0.418249  0.375648  \n",
       "302003.pgm  0.700063  0.665989  0.639136  0.615725  \n",
       "35070.pgm   0.815345  0.796692  0.768751  0.757586  \n",
       "216066.pgm  0.462882  0.405342  0.354301  0.305052  \n",
       "166081.pgm  0.570448  0.528372  0.485041  0.446398  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('logs/susan_logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1.0\n",
      "5     0.940115\n",
      "10    0.877902\n",
      "15    0.822536\n",
      "20    0.765141\n",
      "25    0.710787\n",
      "30    0.663364\n",
      "35    0.615986\n",
      "40    0.572202\n",
      "45    0.535664\n",
      "50    0.499644\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Get the average of each column\n",
    "average_ssim = results.mean()\n",
    "\n",
    "print(average_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a csv file that contains 30000 values of 3.6 \n",
    "\n",
    "dummy_volts = np.full((30000, 1), 3.6)\n",
    "dummy_volts_df = pd.DataFrame(dummy_volts, columns=['Voltage'])\n",
    "dummy_volts_df.to_csv('logs/dummy_volts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth Path\n",
    "path_to_ground_truth = 'output_images/original/'\n",
    "\n",
    "# Prediction Path\n",
    "path_to_prediction = 'output_images/truncation_45perc/'\n",
    "\n",
    "# Path to Logs\n",
    "\n",
    "path_to_logs = 'logs/f1_truncation_45perc.csv'\n",
    "\n",
    "# For every image in the ground truth folder, calculate the F1 score with the corresponding image in the prediction folder if the image exists. \n",
    "# The log file contains the name of all images in the first column, another field in the second column. The F1 score should get appended in the third column.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "ground_truth_images = os.listdir(path_to_ground_truth)\n",
    "prediction_images = os.listdir(path_to_prediction)\n",
    "\n",
    "log_data = []\n",
    "\n",
    "for image in ground_truth_images:\n",
    "    if image in prediction_images:\n",
    "        original_image = load_pgm_opencv(path_to_ground_truth + image)\n",
    "        approximated_image = load_pgm_opencv(path_to_prediction + image)\n",
    "        f1_score = calculate_f1_score(original_image, approximated_image)\n",
    "        log_data.append([image, f1_score])\n",
    "    else:\n",
    "        log_data.append([image, 'N/A'])\n",
    "        \n",
    "log_df = pd.DataFrame(log_data, columns=['Image', 'F1 Score'])\n",
    "log_df.to_csv(path_to_logs, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
